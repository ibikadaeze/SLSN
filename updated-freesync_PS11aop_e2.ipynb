{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import ascii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_nu(t_p,nu_p,F_nup,nu_sed):\n",
    "    '''Calculates a Synchrotron Self-Absorbed Spectrum for given input parameters.\n",
    "    \n",
    "    Parameters:\n",
    "    t_p (days): Time of SSA peak - should be single number\n",
    "    nu_p (GHz): Frequency of SSA peak - should be single number\n",
    "    F_nup (mJy): Flux of SSA peak - should be single number\n",
    "    nu (GHz): Frequencies at which you want the SSA spectrum to be calculated at. Likely an array.\n",
    "    \n",
    "    Outputs:\n",
    "    Fnu (mJy): the flux of the SSA. This is an array with values associated with each value of input array nu.\n",
    "    '''\n",
    "    \n",
    "    m = 0.88 #using stAandard model\n",
    "    p = 3.0 #using standard model\n",
    "    a = (2*m)+0.5\n",
    "    b = (p+5-(6*m))/2\n",
    "    t=t_p\n",
    "    Fnu = F_nup*1.582*(t/t_p)**a*(nu_sed/nu_p)**(5/2)*(1-np.exp(-(t/t_p)**(-(a+b))*(nu_sed/nu_p)**(-(p+4)/2)))\n",
    "    \n",
    "    return Fnu\n",
    "\n",
    "\n",
    "def SSA_props(t_p,nu_p,F_nup,D_L,f=0.5,alpha=1e-4,vw=100,epsilon_b=0.1):\n",
    "    '''Calculates Synchroton Self-Absorption properties for given input parameters.\n",
    "    \n",
    "    Inputs:\n",
    "    t_p (days): Time of SSA peak - likely a single number\n",
    "    nu_p (GHz): Frequency of SSA peak - likely a single number\n",
    "    F_nup (mJy): Flux of SSA peak - likely a single number\n",
    "    D (Mpc): angular distance to SN - likely a single number while D_L is the luminosity distance\n",
    "    f (unitless): filling factor (fraction of emitting region). default is 0.5\n",
    "    alpha (unitless): ratio charged particles to magnetic field (epsilon_e/epsilon_b). default 1\n",
    "    v_w (km/s): wind speed. default = 100\n",
    "    epsilon_b (unitless): fraction of shock energy into B-fields. default = 0.1\n",
    "    \n",
    "    Outputs:\n",
    "    R (cm): radius of material \n",
    "    B : magnetic field flux\n",
    "    E : intermal energy of emitting material\n",
    "    v (km/s): expansion velocity of material\n",
    "    M (1d-5 solar masses per year): inferred mass loss rate of progenitor'''\n",
    "    \n",
    "    #angular distance\n",
    "    D = D_L/((1+z)**2)\n",
    "    \n",
    "    #Radius\n",
    "    R = 4.0e14*(alpha)**(-1/19)*(f/0.5)**(-1/19)*(F_nup)**(9/19)*(D)**(18/19)*(nu_p/5)**(-1)\n",
    "\n",
    "    # Magnetic field flux\n",
    "    B = 1.1*(alpha)**(-4/19)*(f/0.5)**(-4/19)*(F_nup)**(-2/19)*(D)**(-4/19)*(nu_p/5)\n",
    "\n",
    "    #Internal energy of the emitting material\n",
    "    E = (1/epsilon_b)*((B**2)/(8* 3.142))*((4*3.142*f*R**3)/3)\n",
    "\n",
    "    #expansion velocity in km/s\n",
    "    v = (R/t_p)*1.1574e-10\n",
    "\n",
    "    #pre-explosion mass-loss in 1e-5 solar mass per year\n",
    "    M = 1.0*(alpha)**(-8/19)*(epsilon_b/0.1)*(f/0.5)**(-8/19)*(F_nup)**(-4/19)*(D)**(-4/19)*(nu_p/5)*(t_p/10)*(vw/1000)\n",
    "    \n",
    "   \n",
    "\n",
    "    return R,B,E,v,M\n",
    "\n",
    "\n",
    "def taufreefree(M,R,nu):\n",
    "    '''Calculates the free free optical depth for a given set of parameters.\n",
    "    \n",
    "    Inputs:\n",
    "    M (1d-5 solar masses per year): mass loss rate\n",
    "    R (cm): radius of emitting material\n",
    "    nu (GHz): Frequencies at which you want tau-ff to be calculated at. Likely an array.\n",
    "    \n",
    "    Outputs:\n",
    "    tau_ff (unitless): the free-free optical depth, calculated at same frequences as input array nu'''\n",
    "\n",
    "    Z_ave = 1  # Average metallicity 1= pure H. 5.4 for a massive star\n",
    "    miu = 1 # mean molecular weight of electrons. 1= pure H  1.9 is for a massive star.\n",
    "    vw_cgs = 100 * 1e5 # assumed wind velocity in cgs (cm/s). Take this as 1000 * 10^5 for now. (i.e. 1000 km/s in cgs)\n",
    "    T = 10**4 # temperature of the material absorbing in K.  10^4 is a good starting point. \n",
    "        \n",
    "    M_cgs =  M * 1e-5 * 6.307e+25 #mass loss rate in cgs units\n",
    "    \n",
    "    tau_ff = 2.021e25*M_cgs**2*Z_ave/(miu**2*nu**(2.1)*R**3*vw_cgs**2*T**(1.35))  \n",
    "    \n",
    "    return tau_ff\n",
    "\n",
    "def den(M,R):\n",
    "    vw_cgs = 100 * 1e5\n",
    "    M_cgs =  M * 1e-5 * 6.307e+25 #mass loss rate in cgs units \n",
    "        #density of the CSM\n",
    "    density = M_cgs/(4*3.142*R**2*vw_cgs)\n",
    "    \n",
    "    return density\n",
    "#freqs,SED = F_nu(1224.288326 , 8,  0.0272)       \n",
    "#R2,B2,E2,v2,M2 = SSA_props(1224.288326 , 8,  0.0272,880) \n",
    "#tauff=taufreefree(M2,R2,freqs)\n",
    "#tauff=taufreefree(4,3e14,np.array([2,5,7]))\n",
    "#print(freqs)\n",
    "#print(tauff)\n",
    "#print(R2,B2,E2,v2,M2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define parameters that are specific to the supernova you want to model:###\n",
    "date_expl = 55770.562 - 5 #55736.161 #inferred explosion date\n",
    "date_obs = 57829.76513 # date that radio obs was taken\n",
    "redshift = 0.218 # redshift of object\n",
    "t_p = (date_obs - date_expl)/(1+redshift) # time of observation in days #1261.509031#\n",
    "D_L = 1070.1 # distance to SN in Mpc\n",
    "z = 0.218\n",
    "F_ul = [0.405,0.0258] \n",
    "F_det = [0.0318,0.0155]\n",
    "F_det_err = [0.0095,0.0056]\n",
    "nu_det = [6.05,14.75] #0.0404 #0.0404 # flux of upper limit in mJy\n",
    "nu_ul = [3.00,9.02] # frequency of upper limit in GHz\n",
    "\n",
    "### Define the grid of F_p and nu_p that you want to search over:###\n",
    "F_p = np.logspace(np.log10(0.001),np.log10(1.0),num=50) #mJy (this is an array evenly spaced in log between 0.01 annd 1)\n",
    "nu_p = np.logspace(np.log10(0.05),np.log10(50),num=50) #GHz (this is an array evenly spaced in log between 0.5 annd 50)\n",
    "file_out = 'PS11aop_grid_e2+5A.csv' #File that you will save the results in.\n",
    "\n",
    "#F_p = np.linspace(1,7,num=25) #mJy (this is an array evenly spaced in log between 0.01 annd 1)\n",
    "#nu_p = np.linspace(1,7,num=25) #GHz (this is an array evenly spaced in log between 0.5 annd 50)\n",
    "#file_out = 'PS11aop_grid_e2_allowed_zoom.csv' #File that you will save the results in.\n",
    "\n",
    "\n",
    "### Define array of frequencies to calculate the SSA and SSA+FFA spectrum at ###\n",
    "nu_sed = np.array([0.5,0.7,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15])\n",
    "\n",
    "### Define empty arrays of the values that you want to save for each value in the grid you are searching over: ###\n",
    "Fp_g = [] #peak flux\n",
    "nup_g =[] #peak frequency\n",
    "R_g =[] #radius\n",
    "B_g = [] #Bfield\n",
    "vsh_g = [] #velocity of shock\n",
    "M_g = [] #mass loss rate\n",
    "den_g = []\n",
    "RuledOut_g = [] #flag for whether it is ruled out\n",
    "\n",
    "######### SEARCH OVER GRID ############\n",
    "\n",
    "for F in F_p:\n",
    "    for nu in nu_p:\n",
    "        #calculate SSA\n",
    "        SSA_sed = F_nu(t_p,nu,F,nu_sed)\n",
    "        \n",
    "        #calculate Mass loss rate, Radius, velocity, etc.\n",
    "        R,B,E,v,M = SSA_props(t_p,nu,F,D_L)\n",
    "        \n",
    "        #calculate the density of the CSM\n",
    "        density = den(M,R)\n",
    "       \n",
    "        #calculate tau_ff\n",
    "        tauff = taufreefree(M,R,nu_sed)\n",
    "        \n",
    "        #Correct SED for FFA:\n",
    "        SSA_FFA_sed = SSA_sed*np.exp(-tauff)\n",
    "        \n",
    "        \n",
    "        #Evaluate if this SED is allowed:\n",
    "        RuledOut = False #Assume a default posisition that this combination is allowed.\n",
    "        \n",
    "        #First loop over the upper limits and see if any of them rule it out.\n",
    "        for i in range(len(F_ul)):\n",
    "            freq = nu_ul[i]\n",
    "            flux = F_ul[i]\n",
    "            #Interpolate this SSA+FFA to the frequency of your data point:\n",
    "            flux_test1 = np.interp(nu_ul, nu_sed, SSA_FFA_sed)\n",
    "            if np.any(flux_test1 > flux):\n",
    "                RuledOut = True\n",
    "                break\n",
    "\n",
    "        #Now test against the detections as well:\n",
    "        for i in range(len(F_det)):\n",
    "            flux_test2 = np.interp(nu_det[i], nu_sed, SSA_FFA_sed)\n",
    "            F_upper = F_det[i] + F_det_err[i]\n",
    "            F_lower = F_det[i] - F_det_err[i]\n",
    "\n",
    "            if (flux_test2 > F_upper):\n",
    "                RuledOut = True\n",
    "            if (flux_test2 < F_lower):\n",
    "                RuledOut = True\n",
    "\n",
    "        \n",
    "        # Append the values from this loop into the arrays that we defined above:\n",
    "        Fp_g.append(F) \n",
    "        nup_g.append(nu) \n",
    "        R_g.append(R) \n",
    "        B_g.append(B) \n",
    "        vsh_g.append(v) \n",
    "        M_g.append(M)\n",
    "        den_g.append(density)\n",
    "        RuledOut_g.append(RuledOut) \n",
    " \n",
    "        #It will now go on to the next set in the loop:\n",
    "    \n",
    "# Now it has gone over the whole loop. So write out the results into a data file that you can use later:\n",
    "data = [Fp_g,nup_g,R_g,B_g,vsh_g,M_g,den_g,RuledOut_g]\n",
    "names = ['F_peak','nu_peak','Radius','Bfield','v_shock','Mdot','den','RuledOut']\n",
    "ascii.write(data,file_out,names=names,overwrite=True,format='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'PS11aop_grid_e2+5.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-1272ecbe9445>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mD_L\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1070.1\u001b[0m \u001b[0;31m# distance to SN in Mpc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfile_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'PS11aop_grid_e2+5.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mascii\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#########################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/astropy/io/ascii/ui.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(table, guess, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;31m# through below to the non-guess way so that any problems result in a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# more useful traceback.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0mdat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_guess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfast_reader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mguess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/astropy/io/ascii/ui.py\u001b[0m in \u001b[0;36m_guess\u001b[0;34m(table, read_kwargs, format, fast_reader)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m             \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguessing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m             \u001b[0mdat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m             _read_trace.append({'kwargs': copy.deepcopy(guess_kwargs),\n\u001b[1;32m    449\u001b[0m                                 \u001b[0;34m'Reader'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/astropy/io/ascii/core.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, table)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m         \u001b[0;31m# Get a list of the lines (rows) in the table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m         \u001b[0;31m# Set self.data.data_lines to a slice of lines contain the data rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/astropy/io/ascii/core.py\u001b[0m in \u001b[0;36mget_lines\u001b[0;34m(self, table, newline)\u001b[0m\n\u001b[1;32m    303\u001b[0m             if (hasattr(table, 'read')\n\u001b[1;32m    304\u001b[0m                     or ('\\n' not in table + '' and '\\r' not in table + '')):\n\u001b[0;32m--> 305\u001b[0;31m                 with get_readable_fileobj(table,\n\u001b[0m\u001b[1;32m    306\u001b[0m                                           encoding=self.encoding) as fileobj:\n\u001b[1;32m    307\u001b[0m                     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/astropy/utils/data.py\u001b[0m in \u001b[0;36mget_readable_fileobj\u001b[0;34m(name_or_obj, encoding, cache, show_progress, remote_timeout, sources, http_headers)\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mremote_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msources\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m                 http_headers=http_headers)\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_url\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0mdelete_fds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'PS11aop_grid_e2+5.csv'"
     ]
    }
   ],
   "source": [
    "## MAKE A PLOT OF THE SEDS that are allowed: \n",
    "D_L = 1070.1 # distance to SN in Mpc\n",
    "file_in = 'PS11aop_grid_e2+5.csv'\n",
    "data_plot = ascii.read(file_in)\n",
    "\n",
    "#########################\n",
    "#Set up the plot:\n",
    "#########################\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.autoscale()\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "\n",
    "\n",
    "#Allowed\n",
    "indexa = np.where(data_plot['RuledOut'] == 'False')[0]\n",
    "data_plota = data_plot[indexa]\n",
    "\n",
    "Fcalc = data_plota['F_peak'][0:10]\n",
    "nucalc = data_plota['nu_peak'][0:10]\n",
    "nu_sed=np.logspace(np.log10(0.1),np.log10(50),num=100)\n",
    "\n",
    "###Cycle over the SEDs to show######\n",
    "for i in range(len(Fcalc)):\n",
    "    #calculate SSA\n",
    "    SSA_sed = F_nu(t_p,nucalc[i],Fcalc[i],nu_sed)\n",
    "    \n",
    "    #calculate Mass loss rate, Radius, velocity, etc.\n",
    "    R,B,E,v,M = SSA_props(t_p,nucalc[i],Fcalc[i],D_L)\n",
    "\n",
    "    #calculate tau_ff\n",
    "    tauff = taufreefree(M,R,nu_sed)\n",
    "        \n",
    "    #Correct SED for FFA:\n",
    "    SSA_FFA_sed = SSA_sed*np.exp(-tauff)\n",
    "    \n",
    "    #Plot it:\n",
    "    plt.plot(nu_sed,SSA_FFA_sed,'b',zorder=1,alpha=0.5)\n",
    "\n",
    " #Not allowed\n",
    "indexb = np.where(data_plot['RuledOut'] == 'True')[0]\n",
    "data_plotb = data_plot[indexb]\n",
    "\n",
    "Fcalc1 = data_plotb['F_peak'][0:1800:44]\n",
    "nucalc1 = data_plotb['nu_peak'][0:1800:44]\n",
    "nu_sed1=np.logspace(np.log10(0.1),np.log10(50),num=100)\n",
    "\n",
    "for i in range(len(Fcalc1)):\n",
    "    #calculate SSA\n",
    "    SSA_sed1 = F_nu(t_p,nucalc1[i],Fcalc1[i],nu_sed1)\n",
    "    \n",
    "    #calculate Mass loss rate, Radius, velocity, etc.\n",
    "    R1,B1,E1,v1,M1 = SSA_props(t_p,nucalc1[i],Fcalc1[i],D_L)\n",
    "\n",
    "    #calculate tau_ff\n",
    "    tauff1 = taufreefree(M1,R1,nu_sed1)\n",
    "        \n",
    "    #Correct SED for FFA:\n",
    "    SSA_FFA_sed1 = SSA_sed1*np.exp(-tauff1)\n",
    "    \n",
    "    #Plot it:\n",
    "    plt.plot(nu_sed1,SSA_FFA_sed1,'r',zorder=1,alpha=0.5)\n",
    "    \n",
    "#Overplot the data:\n",
    "#plt.plot(3.0,0.405, 'kv', markersize=10)\n",
    "plt.errorbar(6.0,0.0318,0.0095,fmt ='o',color='lightgreen',markersize=10,elinewidth=4,markeredgecolor='k',markeredgewidth=2)#'ro', markersize=10)\n",
    "plt.plot(9.02,0.0258, 'v', markersize=12,color='xkcd:turquoise',linewidth=4,markeredgecolor='k',markeredgewidth=2)\n",
    "plt.errorbar(14.74,0.0155, 0.0056,fmt='o',color='xkcd:olive',markersize=10,elinewidth=4,markeredgecolor='k',markeredgewidth=2)#, markersize=10)\n",
    "plt.text(1.1,0.07,'Allowed',color = 'b',fontsize=15,bbox={'facecolor': 'b', 'alpha': 0.2, 'pad': 5})\n",
    "plt.text(1.1,0.05,'Not Allowed',color='r',fontsize=15,bbox={'facecolor': 'r', 'alpha': 0.2, 'pad': 5})\n",
    "plt.xlabel(r'$\\nu$ (GHz)', fontsize=20) #Log$_{10}$ t$_{rest}$(days)($\\u03BD$ /5 GHz)', fontsize=14)\n",
    "plt.ylabel('Flux (mJy)', fontsize=20) \n",
    "plt.savefig('multiPS11aop.pdf')\n",
    "plt.title('PS11aop - 2017A')   \n",
    "plt.ylim(5e-3,1e-1)\n",
    "plt.xlim(1,18)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
