{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import ascii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_nu(t_p,nu_p,F_nup,nu_sed):\n",
    "    '''Calculates a Synchrotron Self-Absorbed Spectrum for given input parameters.\n",
    "    \n",
    "    Parameters:\n",
    "    t_p (days): Time of SSA peak - should be single number\n",
    "    nu_p (GHz): Frequency of SSA peak - should be single number\n",
    "    F_nup (mJy): Flux of SSA peak - should be single number\n",
    "    nu (GHz): Frequencies at which you want the SSA spectrum to be calculated at. Likely an array.\n",
    "    \n",
    "    Outputs:\n",
    "    Fnu (mJy): the flux of the SSA. This is an array with values associated with each value of input array nu.\n",
    "    '''\n",
    "    \n",
    "    m = 0.88 #using stAandard model\n",
    "    p = 3.0 #using standard model\n",
    "    a = (2*m)+0.5\n",
    "    b = (p+5-(6*m))/2\n",
    "    t=t_p\n",
    "    Fnu = F_nup*1.582*(t/t_p)**a*(nu_sed/nu_p)**(5/2)*(1-np.exp(-(t/t_p)**(-(a+b))*(nu_sed/nu_p)**(-(p+4)/2)))\n",
    "    \n",
    "    return Fnu\n",
    "\n",
    "\n",
    "def SSA_props(t_p,nu_p,F_nup,D,f=0.5,alpha=1,vw=100,epsilon_b=0.1):\n",
    "    '''Calculates Synchroton Self-Absorption properties for given input parameters.\n",
    "    \n",
    "    Inputs:\n",
    "    t_p (days): Time of SSA peak - likely a single number\n",
    "    nu_p (GHz): Frequency of SSA peak - likely a single number\n",
    "    F_nup (mJy): Flux of SSA peak - likely a single number\n",
    "    D (Mpc): distance to SN - likely a single number\n",
    "    f (unitless): filling factor (fraction of emitting region). default is 0.5\n",
    "    alpha (unitless): ratio charged particles to magnetic field (epsilon_e/epsilon_b). default 1\n",
    "    v_w (km/s): wind speed. default = 100\n",
    "    epsilon_b (unitless): fraction of shock energy into B-fields. default = 0.1\n",
    "    \n",
    "    Outputs:\n",
    "    R (cm): radius of material \n",
    "    B : magnetic field flux\n",
    "    E : intermal energy of emitting material\n",
    "    v (km/s): expansion velocity of material\n",
    "    M (1d-5 solar masses per year): inferred mass loss rate of progenitor'''\n",
    "    \n",
    "\n",
    "    #Radius\n",
    "    R = 4.0e14*(alpha)**(-1/19)*(f/0.5)**(-1/19)*(F_nup)**(9/19)*(D)**(18/19)*(nu_p/5)**(-1)\n",
    "\n",
    "    # Magnetic field flux\n",
    "    B = 1.1*(alpha)**(-4/19)*(f/0.5)**(-4/19)*(F_nup)**(-2/19)*(D)**(-4/19)*(nu_p/5)\n",
    "\n",
    "    #Internal energy of the emitting material\n",
    "    E = (1/epsilon_b)*((B**2)/(8* 3.142))*((4*3.142*f*R**3)/3)\n",
    "\n",
    "    #expansion velocity in km/s\n",
    "    v = (R/t_p)*1.1574e-10\n",
    "\n",
    "    #pre-explosion mass-loss in 1e-5 solar mass per year\n",
    "    M = 1.0*(alpha)**(-8/19)*epsilon_b*(f)**(-8/19)*(F_nup)**(-4/19)*(D)**(-4/19)*(nu_p/5)*(t_p/10)*(vw/1000)\n",
    "    \n",
    "   \n",
    "\n",
    "    return R,B,E,v,M\n",
    "\n",
    "\n",
    "def taufreefree(M,R,nu):\n",
    "    '''Calculates the free free optical depth for a given set of parameters.\n",
    "    \n",
    "    Inputs:\n",
    "    M (1d-5 solar masses per year): mass loss rate\n",
    "    R (cm): radius of emitting material\n",
    "    nu (GHz): Frequencies at which you want tau-ff to be calculated at. Likely an array.\n",
    "    \n",
    "    Outputs:\n",
    "    tau_ff (unitless): the free-free optical depth, calculated at same frequences as input array nu'''\n",
    "\n",
    "    Z_ave = 5.4  # Average metallicity 1= pure H. 5.4 for a massive star\n",
    "    miu = 1.9 # mean molecular weight of electrons. 1= pure H  1.9 is for a massive star.\n",
    "    vw_cgs = 100 * 1e5 # assumed wind velocity in cgs (cm/s). Take this as 1000 * 10^5 for now. (i.e. 1000 km/s in cgs)\n",
    "    T = 10**4 # temperature of the material absorbing in K.  10^4 is a good starting point. \n",
    "        \n",
    "    M_cgs =  M * 1e-5 * 6.307e+25 #mass loss rate in cgs units\n",
    "    \n",
    "    tau_ff = 2.021e25*M_cgs**2*Z_ave/(miu**2*nu**(2.1)*R**3*vw_cgs**2*T**(1.35))  \n",
    "    \n",
    "    return tau_ff\n",
    "\n",
    "def den(M,R):\n",
    "    vw_cgs = 100 * 1e5\n",
    "    M_cgs =  M * 1e-5 * 6.307e+25 #mass loss rate in cgs units \n",
    "        #density of the CSM\n",
    "    density = M_cgs/(4*3.142*R**2*vw_cgs)\n",
    "    \n",
    "    return density\n",
    "#freqs,SED = F_nu(1224.288326 , 8,  0.0272)       \n",
    "#R2,B2,E2,v2,M2 = SSA_props(1224.288326 , 8,  0.0272,880) \n",
    "#tauff=taufreefree(M2,R2,freqs)\n",
    "#tauff=taufreefree(4,3e14,np.array([2,5,7]))\n",
    "#print(freqs)\n",
    "#print(tauff)\n",
    "#print(R2,B2,E2,v2,M2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a Dense GRID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished tp= 100\n",
      "Finished tp= 200\n",
      "Finished tp= 500\n",
      "Finished tp= 800\n",
      "Finished tp= 1000\n",
      "Finished tp= 1200\n",
      "Finished tp= 1500\n",
      "Finished tp= 1800\n",
      "Finished tp= 2000\n",
      "Finished tp= 2200\n",
      "Finished tp= 2500\n",
      "Finished tp= 2800\n",
      "Finished tp= 3000\n",
      "Finished tp= 3200\n",
      "Finished tp= 4000\n",
      "Finished tp= 5000\n",
      "Finished tp= 6000\n",
      "Finished tp= 7000\n",
      "Finished tp= 9000\n"
     ]
    }
   ],
   "source": [
    "##MAKES DENSER GRIDS.\n",
    "\n",
    "#Define a set of times post-explosion that I want to calculate this for; run a massive grid for each and write out.\n",
    "tp = [100,200,500,800,1000,1200,1500,1800,2000,2200,2500,2800,3000,3200,4000,5000,6000,7000,9000]\n",
    "#tp = [100,200,500,800,1000,1200,1500,1800,2000,2200,2500,2800,3000,3067,3200,3255,3500] #days post explosion\n",
    "#tp = [4000,5000,6000,7000,9000]\n",
    "#D = 1070.14 # distance to PS11aop\n",
    "D = 543.4 #Distancce to PS11vo\n",
    "\n",
    "F_p = np.logspace(np.log10(0.0001),np.log10(1.0),num=700) #mJy (this is an array evenly spaced in log between 0.01 annd 1)\n",
    "nu_p = np.logspace(np.log10(0.00005),np.log10(100),num=1000) #GHz (this is an array evenly spaced in log between 0.05 annd 50)\n",
    "\n",
    "### Define empty arrays of the values that you want to save for each value in the grid you are searching over: ###\n",
    "\n",
    "\n",
    "for t in tp:\n",
    "    file_out = 'SSAgrid_11vo_d'+np.str(t)+'.csv'\n",
    "    #file_out = 'SSAgrid_11vo_d'+np.str(t)+'.csv'\n",
    "    Fp_g = [] #peak flux\n",
    "    nup_g =[] #peak frequency\n",
    "    R_g =[] #radius\n",
    "    B_g = [] #Bfield\n",
    "    vsh_g = [] #velocity of shock\n",
    "    M_g = [] #mass loss rate\n",
    "    den_g = []\n",
    "    for F in F_p:\n",
    "        for nu in nu_p:\n",
    "        \n",
    "            #calculate Mass loss rate, Radius, velocity, etc.\n",
    "            R,B,E,v,M = SSA_props(t,nu,F,D)\n",
    "        \n",
    "            # Append the values from this loop into the arrays that we defined above:\n",
    "            Fp_g.append(F) \n",
    "            nup_g.append(nu) \n",
    "            R_g.append(R) \n",
    "            B_g.append(B) \n",
    "            vsh_g.append(v) \n",
    "            M_g.append(M)\n",
    "\n",
    "    # Write out the results into a data file that you can use later:\n",
    "    data = [Fp_g,nup_g,R_g,B_g,vsh_g,M_g]\n",
    "    names = ['F_peak','nu_peak','Radius','Bfield','v_shock','Mdot']\n",
    "    ascii.write(data,file_out,names=names,overwrite=True,format='csv')\n",
    "    print('Finished tp=',t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt to turn this into a Light Curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pick a velocity and Mdot that we are interested in. \n",
    "#PS11aop\n",
    "#velocity = 3500 #km/s\n",
    "#Mdot = 1.14 #1e-5 Msun/year\n",
    "#D = 1070.14 \n",
    "\n",
    "#PS11vo:\n",
    "velocity = 5000 #1537 # 10059\n",
    "correction_factor = 0.1*0.5**(-8./19.)\n",
    "Mdot2 = 10.0#0.348 #2.46 #0.348\n",
    "Mdot = Mdot2*correction_factor\n",
    "print(Mdot2,Mdot)\n",
    "D = 543.4\n",
    "\n",
    "\n",
    "#Fiducial:\n",
    "#velocity = 5000 #km/s\n",
    "#correction_factor = 0.1*0.5**(-8./19.)\n",
    "#Mdot2 = 1\n",
    "#Mdot = Mdot2 * correction_factor \n",
    "#print(Mdot)\n",
    "#D = 1070.14 #Mpc\n",
    "\n",
    "#fileout_LC = \"BestFit_11aop_SSA_v\"+np.str(velocity)+\"_M\"+np.str(Mdot)+\"e-5.csv\"\n",
    "fileout_LC = \"BestFit_11vo_SSA_v\"+np.str(velocity)+\"_M\"+np.str(Mdot2)+\"e-5.csv\"\n",
    "#tp = [100,200,500,800,1000,1200,1500,1800,2000,2200,2500,2800,2905,3000,3200,4000,5000,6000,7000,9000]\n",
    "#tp = [100,200,500,800,1000,1200,1500,1800,2000,2200,2500,2800,3000,3200,3500,4000,5000,6000,7000,9000]\n",
    "tp = [200,500,800,1000,1200,1500,1800,2000,2200,2500,2800,3000,3200]\n",
    "#tp = [100,200,500,800,1000,1200,1500,1800,2000,2200,2500,2800,3000,3067,3200,3255,3500]\n",
    "\n",
    "Fp_best = []\n",
    "nu_p_best = []\n",
    "R_best = []\n",
    "vsh_best = []\n",
    "M_best = []\n",
    "    \n",
    "for t in tp:\n",
    "    #filein='SSAgrid_11aop_d'+np.str(t)+'.csv'\n",
    "    filein='SSAgrid_11vo_d'+np.str(t)+'.csv'\n",
    "    data=ascii.read(filein)\n",
    "    \n",
    "    #Figure out what radius it will be at this time:\n",
    "    radius = velocity*1e5*t*86400.\n",
    "    \n",
    "    #Somehow interpolate the grid to our best fit? Prioritize Mdot? Then radius?\n",
    "    #(1) Find all Mdot within a certain tolerance\n",
    "    toleranceM = Mdot *0.01 #allow a 1% difference.\n",
    "    maxiM = Mdot+toleranceM\n",
    "    miniM = Mdot-toleranceM\n",
    "\n",
    "    index = np.where((data['Mdot'] < maxiM))[0]\n",
    "    data2=data[index]\n",
    "    index2 = np.where(data2['Mdot'] > miniM)[0]\n",
    "    data3=data2[index2]\n",
    "\n",
    "    toleranceR = radius*0.01\n",
    "    maxiR = radius+toleranceR\n",
    "    miniR = radius-toleranceR\n",
    "    index3 = np.where(data3['Radius'] < maxiR)[0]\n",
    "    data4=data3[index3]\n",
    "    index4 = np.where(data4['Radius'] > miniR)[0]\n",
    "    data5=data4[index4]\n",
    "    print('time',t,'numbers',len(index),len(index2),len(index3),len(index4))\n",
    "    \n",
    "    #Run a mini-grid in the region probed by the within 1% case. \n",
    "    \n",
    "    F_p_2 = np.linspace(np.min(data5['F_peak']),np.max(data5['F_peak']),num=50) \n",
    "    nu_p_2 = np.linspace(np.min(data5['nu_peak']),np.max(data5['nu_peak']),num=50) \n",
    "    \n",
    "    Fp_g2 = [] #peak flux\n",
    "    nup_g2 =[] #peak frequency\n",
    "    R_g2 =[] #radius\n",
    "    vsh_g2 = [] #velocity of shock\n",
    "    M_g2 = [] #mass loss rate\n",
    "    \n",
    "    for F in F_p_2:\n",
    "        for nu in nu_p_2:\n",
    "        \n",
    "            #calculate Mass loss rate, Radius, velocity, etc.\n",
    "            R,B,E,v,M = SSA_props(t,nu,F,D)\n",
    "        \n",
    "            # Append the values from this loop into the arrays that we defined above:\n",
    "            Fp_g2.append(F) \n",
    "            nup_g2.append(nu) \n",
    "            R_g2.append(R) \n",
    "            vsh_g2.append(v) \n",
    "            M_g2.append(M)\n",
    "    \n",
    "    #Somehow figure out which in this grid is closest. \n",
    "    frac_diff_R = np.abs((radius - np.array(R_g2))/radius)\n",
    "    frac_diff_M = np.abs((Mdot - np.array(M_g2))/Mdot)\n",
    "    frac_diff = np.sqrt(frac_diff_R**2+frac_diff_M**2)\n",
    "    \n",
    "    indexN = np.where(frac_diff == np.min(frac_diff))[0]\n",
    "    print('time',t,'differentials',frac_diff_R[indexN],frac_diff_M[indexN],frac_diff[indexN])\n",
    "    \n",
    "    #F_temp = \n",
    "    \n",
    "    \n",
    "    Fp_best.append(np.array(Fp_g2)[indexN][0])\n",
    "    nu_p_best.append(np.array(nup_g2)[indexN][0])\n",
    "    R_best.append(np.array(R_g2)[indexN][0])\n",
    "    vsh_best.append(np.array(vsh_g2)[indexN][0])\n",
    "    M_best.append(np.array(M_g2)[indexN][0])\n",
    "\n",
    "\n",
    "tp=np.array(tp)\n",
    "Fp_best = np.array(Fp_best)\n",
    "nu_p_best = np.array(nu_p_best)\n",
    "R_best = np.array(R_best)\n",
    "vsh_best = np.array(vsh_best)\n",
    "M_best = np.array(M_best)\n",
    "# Write out the results into a data file that you can use later:\n",
    "data = [tp,Fp_best,nu_p_best,R_best,vsh_best,M_best]\n",
    "names = ['Time','F_peak','nu_peak','Radius','v_shock','Mdot']\n",
    "ascii.write(data,fileout_LC,names=names,overwrite=True,format='csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
